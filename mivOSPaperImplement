from typing import Any, Dict, Generator, Iterable, List, Optional, Tuple, Union

import csv
import functools
import inspect
import logging
import multiprocessing
import os
import pathlib
import datetime
from dataclasses import dataclass


import matplotlib.pyplot as plt
import neo
import numpy as np
import quantities as pq
from tqdm import tqdm
from typing import Optional

from miv.core.operator import Operator, DataLoader
from miv.signal.spike import ThresholdCutoff
from miv.io.openephys import DataManager
from dataclasses import dataclass
from miv.core.operator import OperatorMixin
from miv.statistics.spiketrain_statistics import interspike_intervals
from miv.core.pipeline import Pipeline
from miv.core.wrapper import wrap_cacher
from miv.visualization.event import plot_spiketrain_raster
#This can be "easily" multiprocessed as there is no dependence on results between channels. We are technically just running the burst function a bunch of times.
# I actually think most for loops in this whole file of code are areas in which the code can be sharded into many instances.
# Need to add aditional check for burst rate to be inbetween 3 and 25 spikes/s
dateandtime = datetime.datetime.now().strftime("m%d%H%M")
@dataclass
class BurstsFilter(OperatorMixin):
    tag = "bursts filter"
    burst_lens = []
    burst_durations = []

    def __post_init__(self):
        super().__init__()
        self.burst_lens = []
        self.burst_durations = []

    @wrap_cacher(cache_tag="burstfilter")
    def __call__(self, spiketrains):
        # Code taken from burst function
        erroneouscopy = spiketrains
        Chnls = spiketrains.number_of_channels
        min_isi = 0.1
        min_len = 10
        for i in range(Chnls) :
            spike_interval = interspike_intervals(spiketrains[i])
            assert spike_interval.all() > 0, "Inter Spike Interval cannot be zero"
            burst_spike = (spike_interval <= min_isi).astype(np.bool_)
            delta = np.logical_xor(burst_spike[:-1], burst_spike[1:])
            interval = np.where(delta)[0]
            if len(interval) % 2:
                interval = np.append(interval, len(delta))
            interval += 1
            interval = interval.reshape([-1, 2])
            mask = np.diff(interval) >= min_len
            interval = interval[mask.ravel(), :]
            Q = np.array(interval)
            spike = np.array(spiketrains[i])
            if np.sum(Q) != 0 :
                erroneouscopy.data[i] = np.concatenate([spike[start:end+1] for start,end in Q])
                start_time = spike[Q[:, 0]]
                end_time = spike[Q[:, 1]]
                self.burst_lens.append(Q[:, 1] - Q[:, 0] + 1)
                self.burst_durations.append(end_time - start_time)
            else :
                erroneouscopy.data[i] = []
        
        return erroneouscopy
    
    def plot_spiketrain(
        self,
        spikestamps,
        show: bool = False,
        save_path: Optional[pathlib.Path] = None,
    ) -> plt.Axes:
        """
        Plot spike train in raster
        """
        t0 = spikestamps.get_first_spikestamp()
        tf = spikestamps.get_last_spikestamp()

        t0 = spikestamps.get_first_spikestamp()
        tf = spikestamps.get_last_spikestamp()

        # Create a single plot with adjusted x-axis limits
        fig, ax = plot_spiketrain_raster(spikestamps, t0, tf)
        if save_path is not None:
            np.save(os.path.join(save_path, "burstlengths"), np.asanyarray(self.burst_lens))
            np.save(os.path.join(save_path, "burstdurations"), np.asanyarray(self.burst_durations))
            #self.burst_lens = []
            #self.burst_durations = []
            plt.savefig(os.path.join(save_path, f"burst_raster.png"))

        if show:
            plt.show()
            plt.close("all")

        return ax

@dataclass
class CrossCorrelograms(OperatorMixin):
    tag = "C XY matrix"

    def __post_init__(self):
        super().__init__()

    @wrap_cacher(cache_tag="CXYmatrix")
    def __call__(self, Xspikestamps, Yspikestamps):
        #if Yspikestamps is None: Yspikestamps = Xspikestamps unsure on if this really works so I will exclude it for now
        spiketimesMega = Xspikestamps.neo()
        Xch = Xspikestamps.number_of_channels
        Ych = Yspikestamps.number_of_channels
        C_XY = [[[0 for _ in range(30)] for _ in range(Ych)] for _ in range(Xch)]
        for X in range(Xch) :
            Ys_binned = np.array([[0 for _ in range(Ych)] for _ in range(30)])
            spikeQ = 0
            for time in spiketimesMega[X].magnitude :
                Ys_binned += Yspikestamps.binning(bin_size=0.01, t_start=time-0.15, t_end=time+0.15, return_count=True).data[:30]
                spikeQ += 1
            Ys_norm = np.rot90(Ys_binned/(spikeQ * 0.01), -1)
            Ys_norm[X] = [0 for _ in range(30)]
            C_XY[X] = Ys_norm
        return C_XY
    
    def plot_CXY(
        self,
        C_XY,
        show: bool = False,
        save_path: Optional[pathlib.Path] = None,
    ) :
        if save_path is not None:
            np.save(os.path.join(save_path, "C_XY"), C_XY)
        

@dataclass
class CorrelationIndex(OperatorMixin):
    tag = "CI XY matrix"

    def __post_init__(self):
        super().__init__()

    def __call__(self, C_XY):
        CHAMOUNT = len(C_XY)
        CI_XY = [[0 for _ in range(CHAMOUNT)] for _ in range(CHAMOUNT)]
        for X in range(CHAMOUNT) :
            for Y in range(CHAMOUNT) :
                if(np.sum(C_XY[X][Y]) == 0) : CI = 0
                else : CI = (C_XY[X][Y][15] + C_XY[X][Y][16]) / np.sum(C_XY[X][Y])
                CI_XY[X][Y] = CI 
        return CI_XY
    
    def plot_stuff(
        self,
        CI_XY,
        show: bool = False,
        save_path: Optional[pathlib.Path] = None,
    ) :
        plots = []
        plt.figure()
        for i, sublist in enumerate(CI_XY):
            x_values = [i+1] * len(sublist)
            y_values = sublist
            plt.scatter(x_values, y_values)
        plots.append(plt.gcf())

        plt.figure()
        plt.imshow(CI_XY, cmap='hot', interpolation='nearest')
        plt.colorbar()
        plots.append(plt.gcf())
        if save_path is not None:
            np.save(os.path.join(save_path, "CI_XY"), CI_XY)
            for i, plot in enumerate(plots):
                plot.savefig(os.path.join(save_path, f"graph({i}).png"))
                plot.clear()
        if show:
            plt.show()

        
        
#Example usage:
path = "D:/Globus"
dataset: DataManager = DataManager(data_collection_path=path)
for i in [0,1,2,3,4,5,6,7,8] :
    data : DataLoader = dataset[i]
    spike_detection: Operator = ThresholdCutoff(cutoff=5.0, dead_time=0.003)
    CXY_matrix: Operator = CrossCorrelograms()
    CI_XY_matrix: Operator = CorrelationIndex() 
    burst_filter: Operator = BurstsFilter()
    
    data >> spike_detection >> burst_filter
    pipeline = Pipeline(burst_filter) 
    pipeline.run(working_directory="results/experiment" + str(i+1))